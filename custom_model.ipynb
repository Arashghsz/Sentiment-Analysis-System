{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"import kagglehub\nimport pandas as pd\n\n# Download latest version\npath = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:57:50.946240Z","iopub.execute_input":"2025-02-04T12:57:50.946514Z","iopub.status.idle":"2025-02-04T12:57:51.998566Z","shell.execute_reply.started":"2025-02-04T12:57:50.946492Z","shell.execute_reply":"2025-02-04T12:57:51.997846Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/imdb-dataset-of-50k-movie-reviews\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:57:52.760781Z","iopub.execute_input":"2025-02-04T12:57:52.761227Z","iopub.status.idle":"2025-02-04T12:58:00.112371Z","shell.execute_reply.started":"2025-02-04T12:57:52.761195Z","shell.execute_reply":"2025-02-04T12:58:00.111745Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n# Encode sentiment (positive -> 1, negative -> 0)\ndf['label'] = (df['sentiment'] == 'positive').astype(int)\n\n# Drop the original sentiment column as we now have encoded labels\ndf = df[['review', 'label']]\n\n# Split the data into training, validation, and testing sets\n# First split into train and temp (80-20 split)\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Split temp into validation and test (50-50 split, resulting in 10-10 split of original data)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n\nprint(\"Training set shape:\", train_df.shape)\nprint(\"Validation set shape:\", val_df.shape)\nprint(\"Test set shape:\", test_df.shape)\n\n# Display a few examples from the training set\nprint(\"\\nSample from training set:\")\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:58:02.849689Z","iopub.execute_input":"2025-02-04T12:58:02.850176Z","iopub.status.idle":"2025-02-04T12:58:04.181591Z","shell.execute_reply.started":"2025-02-04T12:58:02.850147Z","shell.execute_reply":"2025-02-04T12:58:04.180763Z"}},"outputs":[{"name":"stdout","text":"Training set shape: (40000, 2)\nValidation set shape: (5000, 2)\nTest set shape: (5000, 2)\n\nSample from training set:\n                                                  review  label\n39087  That's what I kept asking myself during the ma...      0\n30893  I did not watch the entire movie. I could not ...      0\n45278  A touching love story reminiscent of ¬ëIn the M...      1\n16398  This latter-day Fulci schlocker is a totally a...      0\n13653  First of all, I firmly believe that Norwegian ...      0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:58:07.430520Z","iopub.execute_input":"2025-02-04T12:58:07.430829Z","iopub.status.idle":"2025-02-04T12:58:09.295806Z","shell.execute_reply.started":"2025-02-04T12:58:07.430805Z","shell.execute_reply":"2025-02-04T12:58:09.294908Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89bdd0f83f34845ba4a00c388253760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cff0d972dec49f4b6ddf7df10995ad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d8e13041ed94e8a94f53f1693fd43e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2f8837b3a541a8aebae76b8f5e95bd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"class IMDBDataset(Dataset):\n    def __init__(self, reviews, labels, max_length=256):\n        # Tokenize all reviews at once\n        self.encodings = tokenizer(\n            reviews.tolist(),\n            truncation=True,\n            padding=True,\n            max_length=max_length,\n            return_tensors='pt'\n        )\n        # Convert labels to a tensor (ensuring they are of type long)\n        self.labels = torch.tensor(labels.values, dtype=torch.long)\n\n    def __getitem__(self, idx):\n        # For each key in the encodings dictionary, get the corresponding element for idx\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        # Add the label for the current index\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create dataset objects for training, validation, and testing\ntrain_dataset = IMDBDataset(train_df['review'], train_df['label'])\nval_dataset = IMDBDataset(val_df['review'], val_df['label'])\ntest_dataset = IMDBDataset(test_df['review'], test_df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:58:11.743866Z","iopub.execute_input":"2025-02-04T12:58:11.744190Z","iopub.status.idle":"2025-02-04T12:58:37.643415Z","shell.execute_reply.started":"2025-02-04T12:58:11.744161Z","shell.execute_reply":"2025-02-04T12:58:37.642476Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Print the tokenized output for the first training example\nfirst_example = train_dataset[0]\nprint(\"\\nFirst tokenized training example:\")\nfor key, value in first_example.items():\n    print(f\"{key}: {value}\")\n    \n# To see a human-readable version of the tokenized input:\nprint(\"\\nDecoded tokens from the first training example:\")\nprint(tokenizer.decode(first_example['input_ids']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:58:44.492394Z","iopub.execute_input":"2025-02-04T12:58:44.492820Z","iopub.status.idle":"2025-02-04T12:58:44.502154Z","shell.execute_reply.started":"2025-02-04T12:58:44.492785Z","shell.execute_reply":"2025-02-04T12:58:44.501428Z"}},"outputs":[{"name":"stdout","text":"\nFirst tokenized training example:\ninput_ids: tensor([  101,  2008,  1005,  1055,  2054,  1045,  2921,  4851,  2870,  2076,\n         1996,  2116,  9590,  1010,  7491,  3503,  1010, 25082,  1998,  2236,\n        26865,  2008,  2566,  4168,  3686,  1996,  6391,  2781,  1012,  1996,\n        18539,  2036,  3233,  2039,  2043,  2017,  2228,  1997,  1996,  2028,\n         1011,  8789,  3494,  1010,  2040,  2031,  2061,  2210,  5995,  2008,\n         2009,  2003,  8990,  5263,  2000,  2729,  2054,  6433,  2000,  2068,\n         1012,  2027,  2024,  2074,  6649,  2517, 22330, 27921,  2015,  2005,\n         1996,  2472,  2000,  6865,  2010, 27135,  9029,  2006,  1010,  1037,\n         8476,  2008,  2038,  2042,  2589,  2172,  2488,  1999,  2060, 16547,\n         2119,  2006,  2694,  1998,  1996,  5988,  1012,  1026,  7987,  1013,\n         1028,  1026,  7987,  1013,  1028,  1045,  2442, 18766,  1010,  1045,\n         1005,  1049,  2025,  2428,  2028,  2005, 27963,  2919,  4616,  2076,\n         1037,  2143,  1010,  2021,  2009,  2442,  2022,  2056,  2008, 27969,\n        14854,  2050, 20934, 12866,  1006,  2004,  1996, 18869,  1005,  1055,\n        22889,  4904,  3723,  2190,  2767,  1007,  1998,  2001,  5714, 23564,\n        23630,  1006,  2004,  1996, 11808,  1010, 18917,  2567,  1007,  2020,\n         7078,  6659,  1012,  1045,  2123,  1005,  1056,  2113,  2054,  3772,\n         2082,  2027,  3852,  2013,  1010,  2021,  2065,  1045,  2001,  2068,\n         1045,  1005,  1040,  6611,  2005,  1037,  2440, 25416,  8630,  2695,\n        24748,  1012,  2069, 17015,  2532, 22091,  2319,  1999,  1996,  2599,\n         2535,  9020,  2000, 17894,  1999,  1037,  3459,  1997,  2061,  1011,\n         2170,  2329,  5848,  2008,  2057,  1005,  2222,  2763,  2196,  2963,\n         2013,  2153,  1012,  2012,  2560,  1010,  2008,  1005,  1055,  1996,\n         3246,  1012,  2279,  2051,  1010, 10887,  1037,  2367,  7464,  1012,\n         1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  2178, 23824,\n         2245,  2003,  1996, 22293,  2135,   102])\nattention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\nlabels: 0\n\nDecoded tokens from the first training example:\n[CLS] that ' s what i kept asking myself during the many fights, screaming matches, swearing and general mayhem that permeate the 84 minutes. the comparisons also stand up when you think of the one - dimensional characters, who have so little depth that it is virtually impossible to care what happens to them. they are just badly written cyphers for the director to hang his multicultural beliefs on, a topic that has been done much better in other dramas both on tv and the cinema. < br / > < br / > i must confess, i ' m not really one for spotting bad performances during a film, but it must be said that nichola burley ( as the heroine ' s slutty best friend ) and wasim zakir ( as the nasty, bullying brother ) were absolutely terrible. i don ' t know what acting school they graduated from, but if i was them i ' d apply for a full refund post haste. only samina awan in the lead role manages to impress in a cast of so - called british talent that we ' ll probably never hear from again. at least, that ' s the hope. next time, hire a different scout. < br / > < br / > another intriguing thought is the hideously [SEP]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:58:48.480890Z","iopub.execute_input":"2025-02-04T12:58:48.481205Z","iopub.status.idle":"2025-02-04T12:58:52.995223Z","shell.execute_reply.started":"2025-02-04T12:58:48.481181Z","shell.execute_reply":"2025-02-04T12:58:52.994253Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport evaluate\nfrom transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n\n# ---------------------------\n# Step 1: Load the Pre-Trained Model\n# ---------------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    'distilbert-base-uncased', \n    num_labels=2  # Because we have two classes (positive and negative)\n)\n\n# ---------------------------\n# Step 2: Define the Evaluation Metrics\n# ---------------------------\n# Load the metric objects from the evaluate library\naccuracy_metric = evaluate.load(\"accuracy\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric = evaluate.load(\"recall\")\nf1_metric = evaluate.load(\"f1\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T12:59:02.627457Z","iopub.execute_input":"2025-02-04T12:59:02.627768Z","iopub.status.idle":"2025-02-04T12:59:21.727163Z","shell.execute_reply.started":"2025-02-04T12:59:02.627746Z","shell.execute_reply":"2025-02-04T12:59:21.726551Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983b92d9b3bd4fbe811ed862d627451a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56af3aad2d4440b49478133622ec4189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0022404f9d064b6cbe1e8f12e4f38ba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7120c69fd3d64b40b8ed949e5f62945a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a55b60ebc24ca2877bc2fee692e0f0"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Get the predicted class by taking the argmax of the logits\n    predictions = np.argmax(logits, axis=-1)\n    \n    # Compute each metric\n    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n    precision = precision_metric.compute(predictions=predictions, references=labels)\n    recall = recall_metric.compute(predictions=predictions, references=labels)\n    f1 = f1_metric.compute(predictions=predictions, references=labels)\n    \n    # Return a dictionary with the metric values\n    return {\n        \"accuracy\": accuracy[\"accuracy\"],\n        \"precision\": precision[\"precision\"],\n        \"recall\": recall[\"recall\"],\n        \"f1\": f1[\"f1\"]\n    }\n\n# ---------------------------\n# Step 3: Set Up Training Arguments\n# ---------------------------\ntraining_args = TrainingArguments(\n    output_dir='./results',               # Where to save the model checkpoints\n    num_train_epochs=2,                   # Train for 2 epochs\n    per_device_train_batch_size=16,       # Batch size for training (adjust to 32 if your hardware allows)\n    per_device_eval_batch_size=16,        # Batch size for evaluation\n    learning_rate=5e-5,                   # Learning rate\n    evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n    logging_strategy=\"epoch\",             # Log metrics at the end of each epoch\n    save_strategy=\"epoch\",                # Save model checkpoint at the end of each epoch\n    report_to=\"none\",                     # Disable logging to external platforms (e.g., wandb)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:00:23.032013Z","iopub.execute_input":"2025-02-04T13:00:23.032677Z","iopub.status.idle":"2025-02-04T13:00:23.142321Z","shell.execute_reply.started":"2025-02-04T13:00:23.032649Z","shell.execute_reply":"2025-02-04T13:00:23.141427Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,   # Your training dataset\n    eval_dataset=val_dataset,        # Your validation dataset\n    compute_metrics=compute_metrics  # Our defined metrics function\n)\n\n# ---------------------------\n# Step 5: Fine-Tune the Model\n# ---------------------------\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:00:28.169954Z","iopub.execute_input":"2025-02-04T13:00:28.170406Z","iopub.status.idle":"2025-02-04T13:17:22.505179Z","shell.execute_reply.started":"2025-02-04T13:00:28.170364Z","shell.execute_reply":"2025-02-04T13:17:22.504280Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5000/5000 16:52, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.279600</td>\n      <td>0.251944</td>\n      <td>0.907000</td>\n      <td>0.929899</td>\n      <td>0.880448</td>\n      <td>0.904498</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.140600</td>\n      <td>0.269572</td>\n      <td>0.920000</td>\n      <td>0.917031</td>\n      <td>0.923631</td>\n      <td>0.920319</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training complete!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub\nfrom huggingface_hub import notebook_login","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:18:37.931114Z","iopub.execute_input":"2025-02-04T13:18:37.931452Z","iopub.status.idle":"2025-02-04T13:18:41.444078Z","shell.execute_reply.started":"2025-02-04T13:18:37.931424Z","shell.execute_reply":"2025-02-04T13:18:41.442984Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef395b987604a4da57dbbbca08ccdd8"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Login to Hugging Face\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:20:28.625975Z","iopub.execute_input":"2025-02-04T13:20:28.626289Z","iopub.status.idle":"2025-02-04T13:20:28.643020Z","shell.execute_reply.started":"2025-02-04T13:20:28.626265Z","shell.execute_reply":"2025-02-04T13:20:28.642069Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c5e3ddaaed4451a8b8ab201abc99b5"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom huggingface_hub import notebook_login\n\nmodel_save_path = \".my-finetuned-model\"\ntrainer.model.save_pretrained(model_save_path, safe_serialization=False)\ntokenizer.save_pretrained(model_save_path)\n\nprint(f\"Model and tokenizer saved locally in '{model_save_path}'.\")\n\n# print(\"Logging into Hugging Face Hub...\")\n# notebook_login()\n\ntrainer.push_to_hub(\n    commit_message=\"Initial commit: Fine-tuned DistilBERT on IMDB dataset\",\n)\n\nprint(\"Model has been pushed to the Hugging Face Hub.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:28:15.248986Z","iopub.execute_input":"2025-02-04T13:28:15.249314Z","iopub.status.idle":"2025-02-04T13:28:18.453802Z","shell.execute_reply.started":"2025-02-04T13:28:15.249285Z","shell.execute_reply":"2025-02-04T13:28:18.453034Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved locally in '.my-finetuned-model'.\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Model has been pushed to the Hugging Face Hub.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\nmodel_id = \"arashghsz/results\"  # Update with your actual model repo\n\napi = HfApi()\napi.upload_folder(\n    folder_path=\".my-finetuned-model\",\n    repo_id=model_id,\n    repo_type=\"model\"\n)\n\nprint(\"Tokenizer has been pushed to the Hugging Face Hub.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:33:56.228004Z","iopub.execute_input":"2025-02-04T13:33:56.228331Z","iopub.status.idle":"2025-02-04T13:33:58.263206Z","shell.execute_reply.started":"2025-02-04T13:33:56.228303Z","shell.execute_reply":"2025-02-04T13:33:58.262429Z"}},"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Tokenizer has been pushed to the Hugging Face Hub.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n\nmodel_id = \"arashghsz/my-finetuned-model\"  # Update with your model repo ID\n\n# Load the model and tokenizer\nmodel = AutoModelForSequenceClassification.from_pretrained(model_id)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n# Create a pipeline for text classification\nclassifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n\n# Test inference\ntest_text = \"This movie was fantastic!\"\nresult = classifier(test_text)\n\nprint(result)  # Should output a label (positive/negative) with confidence score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T13:34:25.267983Z","iopub.execute_input":"2025-02-04T13:34:25.268322Z","iopub.status.idle":"2025-02-04T13:34:33.812035Z","shell.execute_reply.started":"2025-02-04T13:34:25.268291Z","shell.execute_reply":"2025-02-04T13:34:33.811174Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe92cff43f1488d98de8e9794592d0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"707e9507a3874039a511126ad431dc22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c9d52bba5f445ffb55b141abfaf3749"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62ac76be092145579b576b66600dc0c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234c7b26838c4a3f8e181a8014ed0bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cacbbaf2cefd40889730060305009e1c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[{'label': 'LABEL_1', 'score': 0.9971451163291931}]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import requests\n\nAPI_URL = \"https://api-inference.huggingface.co/models/arashghsz/my-finetuned-model\"\nAPI_TOKEN = \"\"  # Replace with your actual token\n\nheaders = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\ndata = {\"inputs\": \"This movie was amazing!\"}\n\nresponse = requests.post(API_URL, headers=headers, json=data)\nprint(response.json())  # Should return model predictions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T15:09:54.289303Z","iopub.execute_input":"2025-02-04T15:09:54.289596Z","iopub.status.idle":"2025-02-04T15:09:54.813781Z","shell.execute_reply.started":"2025-02-04T15:09:54.289574Z","shell.execute_reply":"2025-02-04T15:09:54.812854Z"}},"outputs":[{"name":"stdout","text":"[[{'label': 'LABEL_1', 'score': 0.9972766041755676}, {'label': 'LABEL_0', 'score': 0.0027233967557549477}]]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Fine-Tuned DistilBERT Model\n\nModel available on Hugging Face Hub and Youtube demo:  \nüîó [Hugging Face Model Link](https://huggingface.co/arashghsz/my-finetuned-model)\n- [Demo on Youtube](https://www.youtube.com/watch?v=uJmQum-qjiQ)\n- [GitHub repo](https://github.com/Arashghsz/Sentiment-Analysis-System)\n","metadata":{}}]}